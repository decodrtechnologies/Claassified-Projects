{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIMENSIONALITY REDUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content :\n",
    "  > * Feature selection\n",
    "  > * Feature extraction\n",
    "  > * Advantages of dimensionality reduction\n",
    "  > * PCA\n",
    "  > * Practical implementation : Wholesale Customer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement:\n",
    "> * Pandas\n",
    "> * Numpy\n",
    "> * Matplotlib\n",
    "> * Scikit learn\n",
    "> * Ipython\n",
    "> * Visual.py file used for ploting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables.\n",
    "\n",
    "COMPONENTS OF DIMENSIONALITY REDUCTION\n",
    "- feature selection\n",
    "- feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example :We are training a model for predicting the heights of people and we have data with features( weights, color, moles, marital status, gender). We can see that the features like color, moles and marital status are not linked with the heights of people i.e., irrelevant to our problem of finding heights of people. Hence we need to come up with a solution of finding features which are most useful for our task.\n",
    "\n",
    "**Feature selection** : tries to find a subset of the input variables.\n",
    "\n",
    "The three strategies are: \n",
    "1. the filter strategy (e.g. information gain), \n",
    "2. the wrapper strategy (e.g. search guided by accuracy),\n",
    "3. the embedded strategy (selected features add or are removed while building the model based on prediction errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature projection (Feature extraction)** : transforms the data from the high-dimensional space to a space of fewer dimensions. \n",
    "\n",
    "The data transformation may be\n",
    "- linear, as in principal component analysis (PCA),\n",
    "- nonlinear dimensionality reduction techniques also exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of dimensionality reduction**\n",
    "1. It reduces the time and storage space required.\n",
    "2. Removal of multi-collinearity improves the interpretation of the parameters of the machine learning model.\n",
    "3. It becomes easier to visualize the data when reduced to very low dimensions such as 2D or 3D.\n",
    "4. It avoids the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRINCIPAL COMPONENT ANALYSIS(PCA)\n",
    "**UNSUPERVISED LINEAR FEATURE PROJECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is mostly used as a tool in **exploratory data analysis** and for making predictive models. It is often used to visualize genetic distance and relatedness between populations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEPS FOR DIMENSION REDUCTION**\n",
    "1. Organize data as an m√ón matrix, where m is the number of measurement types and n is the number of samples.\n",
    "2. Subtract off the mean for each measurement type.\n",
    "3. Calculate the SVD or the eigenvectors and eigen value of the covariance.\n",
    "4. Now the eigen value with higher value corresponds to eigen vector with high variance.\n",
    "5. Only use those dimension which contain maximum information(ie high eigen values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Implementation\n",
    "### DATA\n",
    "\n",
    "We will be using a [Wholesale customers dataset](https://archive.ics.uci.edu/ml/datasets/Wholesale+customers#) from the [UCI Machine learning repository](https://archive.ics.uci.edu/ml/index.php) which has a very good collection of datasets.\n",
    "\n",
    "Features used in this project:\n",
    "- FRESH\n",
    "- MILK\n",
    "- GROCERY\n",
    "- FROZEN\n",
    "- DETERGENTS_PAPER\n",
    "- DELICATESSEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import neccessary libraries for this project\"\"\"\n",
    "\n",
    "# Import libraries necessary for this project\n",
    "\n",
    "# Allows the use of display() for DataFrames\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"read the csv file using pandas library\"\"\"\n",
    "# Load the wholesale customers dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Display a description of the dataset\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"understand the features of the data by observing few samples\"\"\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select three indices of your choice you wish to sample from the dataset\n",
    "\n",
    "\n",
    "# Create a DataFrame of the chosen samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VISUALISE FEATURE DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Produce a scatter matrix for each pair of features in the data\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING\n",
    "\n",
    " To understand the customer better we need to scale the data and detect the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEATURE SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Scale the data and sample using the natural logarithm and plot the scatter matrix\"\"\"\n",
    "# Scale the data using the natural logarithm\n",
    "\n",
    "\n",
    "# Scale the sample data using the natural logarithm\n",
    "\n",
    "\n",
    "# Produce a scatter matrix for each pair of newly-transformed features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using techniques like PCA can help us understand which compound combination of features can best describe the customer,as it maximises the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Apply PCA by fitting the data with the same number of dimensions as features\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "\n",
    "\n",
    "#  Transform log_samples using the PCA fit above\n",
    "\n",
    "\n",
    "# Generate PCA results plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "**Mention your observation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample log-data after having a PCA transformation applied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMENSIONALITY REDUCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"reduce the dimention from no of features to 2 and visualise biplot\"\"\"\n",
    "\n",
    "# Apply PCA by fitting the good data with only two dimensions\n",
    "\n",
    "# Transform the good data using the PCA fit above\n",
    "\n",
    "\n",
    "# Transform log_samples using the PCA fit above\n",
    "\n",
    "\n",
    "# Create a DataFrame for the reduced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample log-data after applying PCA transformation in two dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a biplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FURTHER READING :\n",
    "- https://en.wikipedia.org/wiki/Principal_component_analysis\n",
    "- https://en.wikipedia.org/wiki/Dimensionality_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
